AirVision/
├── .gitignore
├── data/
│   ├── results/
│   └── videos/
│       ├── example1.mp4
│       ├── example2.mp4
│       ├── example3.mp4
├── handler/
│   ├── __pycache__/
│   ├── __init__.py
│   ├── base.py
│   ├── config.py
│   ├── constants.py
│   ├── heatmap.py
│   ├── predict.py
│   └── track.py
├── models/
│   ├── best.pt
│   └── custom_tracker.yaml
├── gui.py
├── main.py
├── README.md
└── requirements.txt



handler/__init__.py
from .constants import SIZE
from .predict import Predictor
from .track import Tracker



handler/base.py
import glob
import logging
import os
import platform
from abc import ABC, abstractmethod
from collections import defaultdict
from pathlib import Path
from typing import Union

import cv2
import torch
import torchvision
import ultralytics
import yaml
from tqdm import tqdm
from ultralytics import YOLO

logging.disable(logging.CRITICAL)
logger = logging.getLogger("ultralytics")
logger.setLevel(logging.CRITICAL)


class HandlerBase(ABC):
    def __init__(
        self,
        model: Union[str, Path] = "models/best.pt",
        video: Union[str, Path] = "data/videos/cows1.mp4",
        save: Union[str, Path] = "data/results.mp4",
        show: bool = False,
        hide_labels: bool = True,
        draw_lines: bool = True,
        lines_history: int = 0,
        debug=False,
        init_model="l",
        *_,
        **kwargs,
    ):
        self.model = YOLO(model)
        self.video = video
        self.cap = cv2.VideoCapture(video)
        self.counter = set()
        self.show = show
        self.save = save
        self.hide_labels = hide_labels
        self.history = defaultdict(list)
        self.draw_lines = draw_lines
        self.lines_history = lines_history
        self.frame_cnt = 0
        self.debug = debug
        self.init_model = init_model
        for key, value in kwargs.items():
            setattr(self, key, value)
        with open("models/custom_tracker.yaml", "r") as f:
            self.tracker_options = yaml.safe_load(f)

    def process_video(self, skip_frames: int = 0, start_frame: int = 0, **_):
        self.prepare_model()
        print("start processing video with")
        frame_cnt = 0
        with tqdm(
            total=int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            // max(skip_frames, 1)
        ) as pbar:
            while self.cap.isOpened():
                success, frame = self.cap.read()
                if (
                    skip_frames and frame_cnt % skip_frames != 0
                ) or frame_cnt < start_frame:
                    frame_cnt += 1
                    continue
                if success:
                    annotated_frame, frame_obj_cnt = self.annotate_frame(frame)
                    annotated_frame = self.counter_box(
                        annotated_frame, frame_obj_cnt
                    )
                    if self.debug:
                        annotated_frame = self.info_box(annotated_frame)
                    if self.show:
                        cv2.imshow("YOLOv11 Tracking", annotated_frame)
                    else:
                        cv2.imwrite(
                            f"data/results/frame_{frame_cnt:0>4}.jpg",
                            annotated_frame,
                        )
                    if cv2.waitKey(1) & 0xFF == ord("q"):
                        break
                    frame_cnt += 1
                    pbar.update(1)
                else:
                    break
        self.cap.release()
        if self.show:
            cv2.destroyAllWindows()
        print("Total objects count:", len(self.counter))

    @abstractmethod
    def annotate_frame(
        self, frame: cv2.typing.MatLike
    ) -> (cv2.typing.MatLike, int):
        pass

    @abstractmethod
    def draw_history(
        self,
        results: ultralytics.engine.results.Results,
        frame: cv2.typing.MatLike,
    ) -> cv2.typing.MatLike:
        pass

    def prepare_model(self):
        pass

    def custom_box(
        self,
        results: ultralytics.engine.results.Results,
        frame: cv2.typing.MatLike,
    ) -> cv2.typing.MatLike:
        self.frame_cnt += 1
        if self.draw_lines:
            frame = self.draw_history(results, frame)
        boxes = results[0].boxes.xywh.cpu()
        annotated_frame = frame.copy()
        for box in boxes:
            x, y, w, h = box
            cv2.rectangle(
                annotated_frame,
                (int(x - w / 2), int(y - h / 2)),
                (int(x + w / 2), int(y + h / 2)),
                (0, 165, 255),
                3,
            )
        return annotated_frame

    def counter_box(
        self, frame: cv2.typing.MatLike, frame_obj_cnt: int
    ) -> cv2.typing.MatLike:
        cv2.rectangle(frame, (10, 10), (235, 80), (100, 100, 100, 100), -1)
        font = cv2.FONT_HERSHEY_SIMPLEX
        text = f"Total: {len(self.counter)}"
        text_x, text_y = 20, 40
        text_size = 1
        cv2.putText(
            frame, text, (text_x, text_y), font, text_size, (255, 255, 255)
        )
        text = f"Current: {frame_obj_cnt}"
        text_y = 70
        cv2.putText(
            frame, text, (text_x, text_y), font, text_size, (255, 255, 255)
        )
        return frame

    def info_box(self, frame: cv2.typing.MatLike) -> cv2.typing.MatLike:
        cv2.rectangle(frame, (980, 10), (1270, 390), (100, 100, 100, 100), -1)
        font = cv2.FONT_HERSHEY_SIMPLEX
        text = []
        text.append(f"frame: {self.frame_cnt}")
        text.append(f"init model: {self.init_model}")
        imgsz = getattr(self, "imgsz", 640)
        conf = getattr(self, "conf", 0.2)
        text.append(f"imgsz: {imgsz}")
        text.append(f"conf: {conf}")
        text.append(f"draw lines: {self.draw_lines}")
        text.append(f"lines history: {self.lines_history}")
        text.append("")
        text.append(f"cuda: {torch.cuda.is_available()}")
        text.append(f"device: {self.get_device()}")
        text.append(f"torch version: {torch.__version__}")
        text.append(f"torch vision ver: {torchvision.__version__}")
        text.append("")
        for key, val in self.tracker_options.items():
            text.append(f"{key}: {val}")
        text_x, text_y = 990, 40
        for text_y, text_line in enumerate(text, start=1):
            cv2.putText(
                frame,
                text_line,
                (text_x, 20 * text_y + 15),
                font,
                0.6,
                (255, 255, 255),
            )
        return frame

    def save_video(self, framerate: int = 30, **_):
        images = sorted(glob.glob("data/results/*.jpg"))
        if images:
            print("Saving video")
            height, width, _ = cv2.imread(images[0]).shape
            fourcc = cv2.VideoWriter_fourcc(*"mp4v")
            out = cv2.VideoWriter(
                self.save, fourcc, framerate, (width, height)
            )
            for filename in tqdm(images):
                img = cv2.imread(filename)
                out.write(img)
            out.release()
            print("Video saved")
            for filename in tqdm(images):
                os.remove(filename)
            return
        print("No images to save video")

    @staticmethod
    def get_device():
        if platform.system() == "Darwin" and "arm64" in platform.machine():
            return "mps"
        elif torch.cuda.is_available():
            return "0"
        return "cpu"



handler/config.py
import argparse

from handler.constants import SIZE


def configure_argument_parser():
    parser = argparse.ArgumentParser(
        description="Objects detection, tacking and counting with YOLO11 model"
    )

    parser.add_argument(
        "mode",
        choices=("tracking", "predict", "heatmap"),
        help="Choose mode of detection objects",
    )

    parser.add_argument(
        "-m",
        "--model",
        type=str,
        default="models/best.pt",
        help="Path to the YOLOv11 model file.",
    )
    parser.add_argument(
        "-v",
        "--video",
        type=str,
        default="data/videos/cows1.mp4",
        help="Path to the video file for analysis.",
    )
    parser.add_argument(
        "-s",
        "--save",
        type=str,
        default="data/results.mp4",
        help="Path to the save video.",
    )
    parser.add_argument(
        "-S", "--show", action="store_true", help="Display results on screen."
    )

    parser.add_argument(
        "-c",
        "--conf",
        type=float,
        default=0.01,
        help="Confidence threshold for object detection. (from 0 to 1)",
    )
    parser.add_argument(
        "--imgsz",
        choices=SIZE.keys(),
        default="s1K",
        help="Image size for processing.",
    )

    parser.add_argument(
        "--draw_lines",
        action="store_true",
        help="Draw history lines on the video.",
    )
    parser.add_argument(
        "--lines_history",
        type=int,
        default=50,
        help="Number of frames to keep lines history.",
    )

    parser.add_argument(
        "-d", "--debug", action="store_true", help="Debug mode."
    )
    parser.add_argument(
        "--init_model",
        type=str,
        default="YOLO11L",
        help="Initial model name. (for debug data)",
    )

    parser.add_argument(
        "-f",
        "--framerate",
        type=int,
        default=30,
        help="Result video framerate.",
    )
    parser.add_argument(
        "--skip_frames",
        type=int,
        default=0,
        help="Skip frames for better speed of analyzing.",
    )
    parser.add_argument(
        "--start_frame",
        type=int,
        default=0,
        help="First frame of video for better speed of analyzing.",
    )

    return parser



handler/constants.py
SIZE = {
    "s4K": (3840, 2144),
    "s2K": (2560, 1312),
    "s1K": (1920, 1056),
    "sd": (640, 640),
}



handler/heatmap.py
import cv2
import numpy as np

from .base import HandlerBase


class HeatmapGenerator(HandlerBase):
    def __init__(
        self,
        *args,
        alpha: float = 0.4,
        radius: int = 15,
        blur: bool = True,
        **kwargs,
    ):
        super().__init__(*args, **kwargs)
        self.heatmap: np.ndarray | None = None
        self.alpha = alpha
        self.radius = radius
        self.blur = blur
        self.coverage: float = 0.0

    def prepare_model(self):
        self.model.conf = getattr(self, "conf", 0.2)

    def annotate_frame(
        self, frame: cv2.typing.MatLike
    ) -> tuple[cv2.typing.MatLike, int]:
        h, w = frame.shape[:2]
        if self.heatmap is None or self.heatmap.shape != (h, w):
            self.heatmap = np.zeros((h, w), dtype=np.float32)

        results = self.model.predict(
            frame, imgsz=self.imgsz, device=self.get_device()
        )
        dets = results[0]
        boxes = dets.boxes.xywh.cpu().numpy()
        curr_count = len(boxes)

        for x, y, *_ in boxes:
            cx, cy = int(x), int(y)
            if 0 <= cx < w and 0 <= cy < h:
                cv2.circle(
                    self.heatmap, (cx, cy), self.radius, 1.0, thickness=-1
                )

        self.coverage = np.count_nonzero(self.heatmap) / (h * w) * 100

        heat_norm = cv2.normalize(
            self.heatmap, None, 0, 255, cv2.NORM_MINMAX
        ).astype(np.uint8)
        if self.blur:
            heat_norm = cv2.GaussianBlur(heat_norm, (0, 0), self.radius / 2)
        heat_vis = cv2.applyColorMap(heat_norm, cv2.COLORMAP_JET)

        blended = cv2.addWeighted(
            heat_vis, self.alpha, frame, 1 - self.alpha, 0
        )

        return blended, curr_count

    def draw_history(self, results, frame):
        return frame

    def counter_box(self, frame, frame_obj_cnt):
        return frame



handler/predict.py
import cv2

from .base import HandlerBase


class Predictor(HandlerBase):
    def prepare_model(self):
        self.model.conf = getattr(self, "conf", 0.2)

    def annotate_frame(
        self, frame: cv2.typing.MatLike
    ) -> tuple[cv2.typing.MatLike, int]:
        results = self.model.predict(
            frame, imgsz=getattr(self, "imgsz", 640), device=self.get_device()
        )

        current_cnt = len(results[0].boxes.xywh)

        if self.hide_labels:
            return self.custom_box(results, frame), current_cnt
        return results[0].plot(), current_cnt

    def draw_history(
        self, results, frame: cv2.typing.MatLike
    ) -> cv2.typing.MatLike:
        return frame



handler/track.py
import cv2
import math
import colorsys
import random
from collections import defaultdict, deque
from ultralytics.engine.results import Results

from .base import HandlerBase


def id_to_color(idx: int) -> tuple[int, int, int]:
    random.seed(idx)
    h = random.random()
    s, v = 0.9, 0.95
    r, g, b = colorsys.hsv_to_rgb(h, s, v)
    return int(b * 255), int(g * 255), int(r * 255)


def smooth_path(
    points: list[tuple[float, float]], k: int = 5
) -> list[tuple[float, float]]:
    if len(points) < 3:
        return points
    smoothed = []
    for i in range(len(points)):
        lo = max(0, i - k)
        hi = min(len(points), i + k + 1)
        xs, ys = zip(*points[lo:hi])
        smoothed.append((sum(xs) / len(xs), sum(ys) / len(ys)))
    return smoothed


class Tracker(HandlerBase):
    def __init__(
        self,
        *args,
        line_thickness: int = 2,
        smooth_tracks: bool = False,
        **kwargs
    ):
        super().__init__(*args, **kwargs)
        default_len = 150
        self.history: defaultdict[int, deque[tuple[float, float]]] = (
            defaultdict(
                lambda: deque(maxlen=self.lines_history or default_len)
            )
        )
        self.line_thickness = line_thickness
        self.smooth_tracks = smooth_tracks

    def annotate_frame(
        self, frame: cv2.typing.MatLike
    ) -> tuple[cv2.typing.MatLike, int]:
        results = self.model.track(
            frame,
            persist=True,
            conf=getattr(self, "conf", 0.2),
            imgsz=getattr(self, "imgsz", 640),
            device=self.get_device(),
            tracker="models/custom_tracker.yaml",
        )
        try:
            ids = results[0].boxes.id.int().cpu().tolist()
            self.counter.update(ids)
            frame_out = (
                self.custom_box(results, frame)
                if self.hide_labels
                else results[0].plot()
            )
            return frame_out, len(ids)
        except Exception:
            return frame, 0

    def draw_history(
        self, results: Results, frame: cv2.typing.MatLike
    ) -> cv2.typing.MatLike:
        boxes = results[0].boxes.xywh.cpu()
        ids = results[0].boxes.id.int().cpu().tolist()

        for (x, y, w, h), tid in zip(boxes, ids):
            cx, cy = float(x), float(y)
            self.history[tid].append((cx, cy))

        active = set(ids)
        for tid in list(self.history):
            if tid not in active and len(self.history[tid]) < 2:
                self.history.pop(tid, None)

        for tid, pts in self.history.items():
            if len(pts) < 2:
                continue

            path = list(pts)
            if self.smooth_tracks:
                path = smooth_path(path)

            base_color = id_to_color(tid)
            n = len(path) - 1

            for i, (p1, p2) in enumerate(zip(path[:-1], path[1:])):
                alpha = (i + 1) / n
                col = tuple(int(c * alpha) for c in base_color)
                cv2.line(
                    frame,
                    (int(p1[0]), int(p1[1])),
                    (int(p2[0]), int(p2[1])),
                    col,
                    self.line_thickness,
                    lineType=cv2.LINE_AA,
                )

            p1, p2 = path[-2], path[-1]
            if math.hypot(p2[0] - p1[0], p2[1] - p1[1]) > 5:
                cv2.arrowedLine(
                    frame,
                    (int(p1[0]), int(p1[1])),
                    (int(p2[0]), int(p2[1])),
                    base_color,
                    self.line_thickness + 1,
                    tipLength=0.3,
                    line_type=cv2.LINE_AA,
                )

        return frame



gui.py
import sys
import os
import time
import cv2
from PyQt5.QtWidgets import (
    QApplication,
    QWidget,
    QLabel,
    QPushButton,
    QFileDialog,
    QComboBox,
    QVBoxLayout,
    QHBoxLayout,
    QSpinBox,
    QSlider,
    QCheckBox,
    QLineEdit,
    QTextEdit,
    QProgressBar,
    QFormLayout,
    QSizePolicy,
    QTabWidget,
)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QMutex, QWaitCondition
from PyQt5.QtGui import QImage, QPixmap
import argparse


class DetectionThread(QThread):
    frame_ready = pyqtSignal(QImage)
    stats_ready = pyqtSignal(int, int, float, float)
    progress = pyqtSignal(int)
    log = pyqtSignal(str, str)
    finished = pyqtSignal()

    def __init__(self, args):
        super().__init__()
        self.args = args
        self._paused = False
        self._stopped = False
        self._m = QMutex()
        self._wait = QWaitCondition()

    def pause(self):
        self._m.lock()
        self._paused = True
        self._m.unlock()

    def resume(self):
        self._m.lock()
        self._paused = False
        self._wait.wakeAll()
        self._m.unlock()

    def stop(self):
        self._m.lock()
        self._stopped = True
        if self._paused:
            self._paused = False
            self._wait.wakeAll()
        self._m.unlock()

    def run(self):
        try:
            from handler.constants import SIZE
            from handler.heatmap import HeatmapGenerator
            from handler.predict import Predictor
            from handler.track import Tracker

            cfg = vars(self.args).copy()
            cfg["imgsz"] = SIZE.get(self.args.imgsz, SIZE["s1K"])
            detector = {
                "tracking": Tracker(**cfg),
                "predict": Predictor(**cfg),
                "heatmap": HeatmapGenerator(**cfg),
            }[self.args.mode]
            detector.prepare_model()

            cap = cv2.VideoCapture(self.args.video)
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 1
            idx = 0
            t_prev = time.time()
            fps = 0.0
            writer = None
            if self.args.save:
                fourcc = cv2.VideoWriter_fourcc(*"mp4v")

            while cap.isOpened():
                self._m.lock()
                if self._stopped:
                    self._m.unlock()
                    break
                if self._paused:
                    self._wait.wait(self._m)
                self._m.unlock()

                ok, frame = cap.read()
                if not ok:
                    break
                annotated, aux = detector.annotate_frame(frame)

                if self.args.save and writer is None:
                    h, w = annotated.shape[:2]
                    writer = cv2.VideoWriter(
                        self.args.save, fourcc, self.args.framerate, (w, h)
                    )
                if writer is not None:
                    writer.write(annotated)

                if self.args.mode == "tracking":
                    current = int(aux)
                    total_unique = len(detector.counter)
                    coverage = -1.0
                elif self.args.mode == "predict":
                    current = int(aux)
                    total_unique = -1
                    coverage = -1.0
                else:
                    current = -1
                    total_unique = -1
                    coverage = float(getattr(detector, "coverage", 0.0))

                now = time.time()
                dt = now - t_prev
                t_prev = now
                if dt > 0:
                    fps = 0.8 * fps + 0.2 * (1.0 / dt)
                self.stats_ready.emit(current, total_unique, coverage, fps)

                rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb.shape
                qimg = QImage(rgb.data, w, h, ch * w, QImage.Format_RGB888)
                self.frame_ready.emit(qimg.copy())

                idx += 1
                self.progress.emit(int(idx * 100 / total))
                self.log.emit(f"Frame {idx}/{total}", "info")
                self.msleep(max(1, int(1000 / self.args.framerate)))

            cap.release()
            if writer:
                writer.release()
                self.log.emit(f"Video saved to {self.args.save}", "success")
            self.log.emit("Processing finished.", "success")
        except Exception as e:
            self.log.emit(f"Error: {e}", "error")
        finally:
            self.finished.emit()


class GUI(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Object Counter with YOLOv11")
        self.resize(1200, 720)
        self._build_ui()
        self._update_mode_panels(self.mode_combo.currentText())

    def _browse(self, le, filt, save=False):
        dlg = QFileDialog.getSaveFileName if save else QFileDialog.getOpenFileName
        path, _ = dlg(self, "Select file", "", filt)
        if path:
            le.setText(path)

    def _make_row(self, placeholder, filt, save=False):
        le = QLineEdit(placeholder)
        btn = QPushButton("Save…" if save else "Browse…")
        btn.clicked.connect(lambda: self._browse(le, filt, save))
        h = QHBoxLayout()
        h.setContentsMargins(0, 0, 0, 0)
        h.addWidget(le)
        h.addWidget(btn)
        container = QWidget()
        container.setLayout(h)
        return le, container

    def _build_ui(self):
        # Left panel
        self.mode_combo = QComboBox()
        self.mode_combo.addItems(["tracking", "predict", "heatmap"])
        self.mode_combo.currentTextChanged.connect(self._update_mode_panels)

        mode_layout = QHBoxLayout()
        mode_layout.addWidget(QLabel("Mode:"))
        mode_layout.addWidget(self.mode_combo)
        mode_layout.addStretch(1)

        self.tabs = QTabWidget()
        self.tabs.addTab(self._common_tab(), "Common")
        self.tabs.addTab(self._track_tab(), "Tracking")
        self.tabs.addTab(self._heat_tab(), "Heatmap")

        # Control buttons with larger size and press effects
        self.start_btn = QPushButton("Start")
        self.start_btn.setStyleSheet(
            """
            QPushButton {
                background-color: #28a745;
                color: #fff;
                border-radius: 6px;
                padding: 12px 20px;
            }
            QPushButton:pressed {
                background-color: #218838;
            }
            """
        )
        self.pause_btn = QPushButton("Pause")
        self.pause_btn.setStyleSheet(
            """
            QPushButton {
                background-color: #6c757d;
                color: #fff;
                border-radius: 6px;
                padding: 12px 20px;
            }
            QPushButton:pressed {
                background-color: #5a6268;
            }
            """
        )
        self.pause_btn.setEnabled(False)
        self.stop_btn = QPushButton("Stop")
        self.stop_btn.setStyleSheet(
            """
            QPushButton {
                background-color: #d9534f;
                color: #fff;
                border-radius: 6px;
                padding: 12px 20px;
            }
            QPushButton:pressed {
                background-color: #c9302c;
            }
            """
        )
        self.stop_btn.setEnabled(False)

        # Connect signals
        self.start_btn.clicked.connect(self._on_start)
        self.pause_btn.clicked.connect(self._on_pause)
        self.stop_btn.clicked.connect(self._on_stop)

        ctrl_layout = QHBoxLayout()
        ctrl_layout.addWidget(self.start_btn)
        ctrl_layout.addWidget(self.pause_btn)
        ctrl_layout.addWidget(self.stop_btn)

        left_layout = QVBoxLayout()
        left_layout.addLayout(mode_layout)
        left_layout.addWidget(self.tabs)
        left_layout.addLayout(ctrl_layout)
        left_layout.addStretch(1)
        left_widget = QWidget()
        left_widget.setLayout(left_layout)
        left_widget.setFixedWidth(360)

        # Right panel
        self.video_lbl = QLabel()
        self.video_lbl.setAlignment(Qt.AlignCenter)
        self.video_lbl.setStyleSheet("background:#000")
        self.video_lbl.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)

        self.progress = QProgressBar()
        self.progress.setAlignment(Qt.AlignCenter)

        self.current = QLabel("Current: —")
        self.total = QLabel("Total: —")
        self.coverage = QLabel("Coverage: —")
        self.fps_lbl = QLabel("FPS: —")
        for lbl in (self.current, self.total, self.coverage, self.fps_lbl):
            lbl.setStyleSheet("font-weight:600; font-size:14px;")
        stats_layout = QHBoxLayout()
        stats_layout.addWidget(self.current)
        stats_layout.addWidget(self.total)
        stats_layout.addWidget(self.coverage)
        stats_layout.addWidget(self.fps_lbl)
        stats_widget = QWidget()
        stats_widget.setLayout(stats_layout)

        self.log = QTextEdit()
        self.log.setReadOnly(True)
        self.log.setStyleSheet("background:#1e1e1e; color:#d1d1d1;")

        right_layout = QVBoxLayout()
        right_layout.addWidget(self.video_lbl, 5)
        right_layout.addWidget(self.progress)
        right_layout.addWidget(stats_widget)
        right_layout.addWidget(self.log, 2)
        right_widget = QWidget()
        right_widget.setLayout(right_layout)

        main_layout = QHBoxLayout(self)
        main_layout.addWidget(left_widget)
        main_layout.addWidget(right_widget)

    def _common_tab(self):
        f = QFormLayout()
        f.setLabelAlignment(Qt.AlignRight)
        self.model_le, mW = self._make_row("models/best.pt", "*.pt")
        f.addRow("Model:", mW)
        self.video_le, vW = self._make_row("data/videos/cows1.mp4", "*.mp4")
        f.addRow("Video:", vW)
        self.save_le, sW = self._make_row("data/result.mp4", "*.mp4", save=True)
        f.addRow("Output:", sW)
        self.imgsz = QComboBox()
        self.imgsz.addItems(["sd", "s1K", "s2K", "s4K"])
        f.addRow("Frame size:", self.imgsz)

        self.conf_s = QSlider(Qt.Horizontal)
        self.conf_s.setRange(1, 100)
        self.conf_s.setValue(20)
        self.conf_val = QLabel("0.20")
        self.conf_s.valueChanged.connect(
            lambda v: self.conf_val.setText(f"{v/100:.2f}")
        )
        conf_w = QWidget()
        conf_h = QHBoxLayout()
        conf_h.setContentsMargins(0, 0, 0, 0)
        conf_h.addWidget(self.conf_s)
        conf_h.addWidget(self.conf_val)
        conf_w.setLayout(conf_h)
        f.addRow("Confidence:", conf_w)

        self.skip_s = QSlider(Qt.Horizontal)
        self.skip_s.setRange(0, 100)
        self.skip_s.setValue(0)
        self.skip_val = QLabel("0")
        self.skip_s.valueChanged.connect(lambda v: self.skip_val.setText(str(v)))
        skip_w = QWidget()
        skip_h = QHBoxLayout()
        skip_h.setContentsMargins(0, 0, 0, 0)
        skip_h.addWidget(self.skip_s)
        skip_h.addWidget(self.skip_val)
        skip_w.setLayout(skip_h)
        f.addRow("Skip frames:", skip_w)

        self.start_spin = QSpinBox()
        self.start_spin.setRange(0, 10**7)
        f.addRow("Start frame:", self.start_spin)
        self.hide_cb = QCheckBox("Hide labels")
        f.addRow(self.hide_cb)
        w = QWidget()
        w.setLayout(f)
        return w

    def _track_tab(self):
        f = QFormLayout()
        f.setLabelAlignment(Qt.AlignRight)

        self.draw_cb = QCheckBox("Draw trajectories")
        self.draw_cb.stateChanged.connect(self._toggle_track)
        f.addRow(self.draw_cb)

        self.tail_s = QSlider(Qt.Horizontal)
        self.tail_s.setRange(1, 500)
        self.tail_s.setValue(50)
        self.tail_val = QLabel("50")
        self.tail_s.valueChanged.connect(lambda v: self.tail_val.setText(str(v)))
        tail_w = QWidget()
        tail_h = QHBoxLayout()
        tail_h.setContentsMargins(0, 0, 0, 0)
        tail_h.addWidget(self.tail_s)
        tail_h.addWidget(self.tail_val)
        tail_w.setLayout(tail_h)
        f.addRow("Tail length:", tail_w)

        self.thick_spin = QSpinBox()
        self.thick_spin.setRange(1, 10)
        self.thick_spin.setValue(2)
        f.addRow("Line thickness:", self.thick_spin)

        self._toggle_track()

        w = QWidget()
        w.setLayout(f)
        return w

    def _heat_tab(self):
        f = QFormLayout()
        f.setLabelAlignment(Qt.AlignRight)

        self.alpha_s = QSlider(Qt.Horizontal)
        self.alpha_s.setRange(5, 100)
        self.alpha_s.setValue(40)
        self.alpha_val = QLabel("0.40")
        self.alpha_s.valueChanged.connect(
            lambda v: self.alpha_val.setText(f"{v/100:.2f}")
        )
        alpha_w = QWidget()
        alpha_h = QHBoxLayout()
        alpha_h.setContentsMargins(0, 0, 0, 0)
        alpha_h.addWidget(self.alpha_s)
        alpha_h.addWidget(self.alpha_val)
        alpha_w.setLayout(alpha_h)
        f.addRow("Alpha:", alpha_w)

        self.radius_s = QSlider(Qt.Horizontal)
        self.radius_s.setRange(1, 100)
        self.radius_s.setValue(15)
        self.radius_val = QLabel("15")
        self.radius_s.valueChanged.connect(lambda v: self.radius_val.setText(str(v)))
        radius_w = QWidget()
        radius_h = QHBoxLayout()
        radius_h.setContentsMargins(0, 0, 0, 0)
        radius_h.addWidget(self.radius_s)
        radius_h.addWidget(self.radius_val)
        radius_w.setLayout(radius_h)
        f.addRow("Radius:", radius_w)

        self.blur_cb = QCheckBox("Blur heatmap")
        f.addRow(self.blur_cb)

        w = QWidget()
        w.setLayout(f)
        return w

    def _toggle_track(self):
        enabled = self.draw_cb.isChecked()
        self.tail_s.setEnabled(enabled)
        self.thick_spin.setEnabled(enabled)

    def _update_mode_panels(self, mode):
        self.tabs.setTabVisible(1, mode == "tracking")
        self.tabs.setTabVisible(2, mode == "heatmap")

    def _on_start(self):
        args = argparse.Namespace(
            mode=self.mode_combo.currentText(),
            model=self.model_le.text(),
            video=self.video_le.text(),
            save=self.save_le.text(),
            imgsz=self.imgsz.currentText(),
            conf=self.conf_s.value() / 100,
            skip_frames=self.skip_s.value(),
            start_frame=self.start_spin.value(),
            hide_labels=self.hide_cb.isChecked(),
            draw_lines=self.draw_cb.isChecked(),
            lines_history=self.tail_s.value(),
            line_thickness=self.thick_spin.value(),
            alpha=self.alpha_s.value() / 100,
            radius=self.radius_s.value(),
            blur=self.blur_cb.isChecked(),
            debug=False,
            init_model="GUI",
            framerate=30,
            show=False,
        )
        self.thread = DetectionThread(args)
        self.thread.frame_ready.connect(self._show_frame)
        self.thread.stats_ready.connect(self._show_stats)
        self.thread.progress.connect(self.progress.setValue)
        self.thread.log.connect(self._append_log)
        self.thread.finished.connect(self._on_finish)

        self.start_btn.setEnabled(False)
        self.pause_btn.setEnabled(True)
        self.stop_btn.setEnabled(True)
        self.pause_btn.setText("Pause")
        self.progress.setValue(0)
        self.log.clear()
        self._reset_stats()
        self.thread.start()

    def _on_pause(self):
        if self.pause_btn.text() == "Pause":
            self.thread.pause()
            self.pause_btn.setText("Resume")
        else:
            self.thread.resume()
            self.pause_btn.setText("Pause")

    def _on_stop(self):
        self.thread.stop()

    def _on_finish(self):
        self.start_btn.setEnabled(True)
        self.pause_btn.setEnabled(False)
        self.stop_btn.setEnabled(False)

    def _show_frame(self, img):
        pix = QPixmap.fromImage(img).scaled(
            self.video_lbl.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation
        )
        self.video_lbl.setPixmap(pix)

    def _show_stats(self, curr, tot, cov, fps):
        self.current.setText(f"Current: {curr}" if curr >= 0 else "Current: —")
        self.total.setText(f"Total: {tot}" if tot >= 0 else "Total: —")
        self.coverage.setText(f"Coverage: {cov:.1f}%" if cov >= 0 else "Coverage: —")
        self.fps_lbl.setText(f"FPS: {fps:.1f}")

    def _append_log(self, msg, lvl):
        cmap = {"info": "#d1d1d1", "success": "#5cb85c", "error": "#ff5c5c"}
        color = cmap.get(lvl, "#d1d1d1")
        self.log.append(f"<span style='color:{color}'>{msg}</span>")

    def _reset_stats(self):
        self.current.setText("Current: —")
        self.total.setText("Total: —")
        self.coverage.setText("Coverage: —")
        self.fps_lbl.setText("FPS: —")


if __name__ == "__main__":
    os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
    app = QApplication(sys.argv)
    win = GUI()
    win.show()
    sys.exit(app.exec_())



main.py
import os

from handler.config import configure_argument_parser
from handler.constants import SIZE
from handler.heatmap import HeatmapGenerator
from handler.predict import Predictor
from handler.track import Tracker

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"


def main():
    arg_parser = configure_argument_parser()
    args = arg_parser.parse_args()
    attrs = {
        key: value for key, value in args.__dict__.items() if value is not None
    }
    attrs["imgsz"] = SIZE.get(args.__dict__.get("imgsz"), SIZE["s1K"])

    detector = (
        Tracker(**attrs)
        if args.mode == "tracking"
        else (
            Predictor(**attrs)
            if args.mode == "predict"
            else HeatmapGenerator(**attrs)
        )
    )

    detector.process_video(**attrs)

    if args.save:
        detector.save_video(**attrs)


if __name__ == "__main__":
    main()



requirements.txt
matplotlib==3.10.3
numpy==2.3.0
opencv_python==4.11.0.86
PyQt5==5.15.11
PyQt5_sip==12.17.0
PyYAML==6.0.2
PyYAML==6.0.2
torch==2.7.1
torchvision==0.22.1
tqdm==4.67.1
ultralytics==8.3.151
